# Proyecto OpenData - Procesamiento de Datos

## ‚ú® Prop√≥sito del Proyecto
Este proyecto tiene como objetivo la **ingesti√≥n, transformaci√≥n y almacenamiento** de datos abiertos relacionados con la poblaci√≥n (u otras tem√°ticas), permitiendo su procesamiento mediante **Apache Spark** y **Delta Lake**, y ofreciendo flexibilidad para el manejo de m√∫ltiples ficheros de distintos a√±os.

## üîé Descripci√≥n General
1. **Entrada m√∫ltiple y concurrente**: El sistema puede leer uno o varios ficheros CSV simult√°neamente, aprovechando la concurrencia (via `ThreadPoolExecutor`) cuando supera ciertos umbrales de tama√±o o n√∫mero de ficheros.
2. **Pipeline flexible (metadata.json)**: La configuraci√≥n de entradas, transformaciones y salidas se define en un archivo `metadata.json`, que especifica c√≥mo leer, qu√© campos agregar o filtrar, y a qu√© formatos/ubicaciones escribir.
3. **Transformaciones gen√©ricas**: Se pueden a√±adir campos (`AddFieldsTransformation`), aplicar filtros (`FilterTransformation`), y otras operaciones que se definan en la metadata.
4. **Almacenamiento en JSON / Delta**: Permite tanto la generaci√≥n de archivos JSON (sobrescribiendo el √∫ltimo resultado o acumulando hist√≥ricos) como la escritura en tablas Delta (con `append` o `merge`), lo que facilita la actualizaci√≥n incremental de datos.

## üìÇ Estructura del Pipeline
1. **Lectura de Datos**:
    - Se leen los a√±os a procesar desde un fichero `years.txt` (por ejemplo, 2024 y 2025).
    - Por cada a√±o, se reemplaza `{{ year }}` en la ruta de entrada para obtener la ruta CSV real.
    - Si el total de datos es grande (> 500 MB) o el n√∫mero de ficheros supera 5, la lectura se realiza en paralelo (multithreading). De lo contrario, se hace secuencialmente para evitar overhead.

2. **Transformaciones** (definidas en `metadata.json`):
    - **Add Fields**: se pueden a√±adir columnas como `domain`, `load_date` u otras.
    - **Filter**: se filtran filas (por ejemplo, descartar `sexo != 'Ambos sexos'`).
    - Otras transformaciones futuras podr√≠an implementarse (p.ej. agregaciones, joins, etc.).

3. **Outputs / Salidas**:
    - **JSON**:
        - Archivo ‚Äúlast‚Äù en modo *overwrite* para los datos m√°s recientes.
        - Archivo ‚Äúhistoric‚Äù en modo *append* (particionado por `load_date`).
    - **Delta**:
        - Tabla en modo *merge* (ejemplo: `opendata_demo`), usando `provincia` y `municipio` como primary keys.
        - Tabla en modo *append* (ejemplo: `raw_opendata_demo`).

4. **Gesti√≥n de Metadatos**:
    - Se usa un **singleton** (`MetadataManager`) que carga el JSON solo una vez.
    - El pipeline consulta esa metadata para saber qu√© entradas, transformaciones y salidas ejecutar.

## üìÖ Ejemplo de Flujo de Trabajo
1. Se lee `metadata.json` para descubrir los ‚Äúdataflows‚Äù configurados (ej., `prueba-acceso`).
2. Se consulta `years.txt` para obtener los a√±os a procesar (ej., 2024 y 2025).
3. **Lectura**: se genera un diccionario `{ 'poblacion2024': df_2024, 'poblacion2025': df_2025, ... }`, ya sea en paralelo o secuencial.
4. **Transformaciones**: se a√±ade la columna `domain = 'demography'`, `load_date = current_date()`, y se filtra `sexo != 'Ambos sexos'`.
5. **Escrituras**:
    - JSON de los √∫ltimos datos en `/data/output/opendata_demo/last` (modo overwrite).
    - JSON hist√≥rico en `/data/output/opendata_demo/historic` (modo append).
    - **Delta**:
        - Merge en la tabla `opendata_demo`, con clave primaria `provincia + municipio` (evitando duplicados).
        - Append en `raw_opendata_demo`.

## üìí Ejemplo de Datos de Entrada
- **Formato CSV** con delimitador `;`.
- Ubicaci√≥n base: `/data/input/opendata_demo/poblacion{{ year }}.csv`.
- Se esperan columnas como: `provincia`, `municipio`, `sexo`, `edad`, `poblacion`, etc.

## ‚è© Lectura en Paralelo vs. Secuencial
- Si se detectan **m√°s de 5 ficheros** o **> 500 MB** de datos, se activa la lectura **en paralelo** mediante `ThreadPoolExecutor`.
- De lo contrario, se procesa cada fichero en un simple bucle secuencial (ver `_read_file`), lo que puede ser m√°s eficiente para datasets peque√±os.

## ‚ôªÔ∏è Deduplicaci√≥n y `_metadata`
- En el proceso de `merge` (dentro de `DeltaWriter`), se incluye la posibilidad de **deduplicar** registros bas√°ndose en una columna `_metadata` (asumida como indicador de versi√≥n o timestamp).
- Si la tabla mantiene varias filas con la misma clave, se aplica una ventana que ordena por `_metadata.desc()` y se queda con la m√°s reciente (`row_number = 1`).

## üìÑ Salidas del Pipeline
| Tipo de Salida          | Ubicaci√≥n                            | Formato | Modo                      | Observaciones                                                           |
|-------------------------|--------------------------------------|---------|---------------------------|-------------------------------------------------------------------------|
| **JSON (Last)**         | `/data/output/opendata_demo/last`    | JSON    | Overwrite                 | Gu√≠a los √∫ltimos datos procesados; normalmente un √∫nico archivo.        |
| **JSON (Historic)**     | `/data/output/opendata_demo/historic`| JSON    | Append (partition `load_date`) | Registra la evoluci√≥n en el tiempo; particionado por `load_date`.       |
| **Delta (Merge)**       | `opendata_demo`                      | Delta   | Merge (por PK)           | Identifica duplicados/upserts en base a `provincia, municipio`.         |
| **Delta (Append)**      | `raw_opendata_demo`                  | Delta   | Append                    | Almacena datos ‚Äúbrutos‚Äù sin merge, √∫til como capa raw o staging.        |

## üåê Casos de Uso
1. **An√°lisis demogr√°fico en distintos a√±os**: Lectura simult√°nea de ficheros (2024, 2025...) e integraci√≥n en tablas Delta.
2. **Hist√≥rico de poblaciones**: Con particionado por `load_date`, se rastrea c√≥mo evoluciona la poblaci√≥n a lo largo del tiempo.
3. **Concurrencia Controlada**: Optimiza la lectura en paralelo si hay muchos ficheros; evita overhead cuando son pocos.

## üöÄ Tecnolog√≠as Utilizadas
- **Apache Spark** (procesamiento distribuido y lectura con `spark.read`).
- **Delta Lake** (ACID, merges, time travel y optimizaciones).
- **Python** (coordinaci√≥n del pipeline, transforms, multithreading).
- **ThreadPoolExecutor** (solo para la fase de lectura cuando se superan umbrales).

Este proyecto incluye tests automatizados con **Pytest** y **Spark**:

1. **`test_compare_changes`**
    - Compara dos ficheros (p.ej. 2024 vs 2025) para detectar diferencias en la columna `total`.
    - Realiza un *full outer join* en base a `provincia, municipio, sexo` y verifica si el valor `total` cambia entre ambos a√±os.
    - Muestra las filas distintas con `DataFrame.show()` y asegura que exista al menos una diferencia.

2. **`test_data_quality`**
    - Revisa la consistencia entre ‚ÄúAmbos sexos‚Äù y la suma de ‚ÄúHombres‚Äù + ‚ÄúMujeres‚Äù en el CSV de un a√±o final (por defecto 2025).
    - Para ello, filtra el dataset en tres subconjuntos: `Ambos sexos`, `Hombres`, `Mujeres`, los junta por `provincia` y `municipio`, y compara.
    - Si `Ambos_sexos` difiere de `Total_Ambos_Sexos`, lo considera un problema de calidad (lo muestra con `show()` y falla el test con un `assert`).

Ambos tests se apoyan en:
- **Un fixture de Spark**: para crear `SparkSession` en modo local (`local[*]`).
- **Funciones utilitarias** que extraen rutas de lectura/escritura y opciones de `spark_options` directamente del `metadata.json`.
- **`pytest`**: para la ejecuci√≥n y reporte de √©xito/fallo.
## üîß Futuras Mejoras
1. **Validaciones de Esquema**: Manejar columnas faltantes o distintas en cada a√±o (uso de `mergeSchema`).
2. **M√©tricas y Alertas**: Incluir logs de rendimiento para saber cu√°ndo la lectura en paralelo es efectiva.
3. **Integraci√≥n con Orquestadores** (Airflow, Luigi, etc.) para programar y monitorizar tareas.
4. **M√°s Transformaciones**: Agregaciones o joins con otros datasets, control de calidad, etc.
